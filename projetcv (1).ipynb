{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "projetcv.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKNo0pFsUhOi"
      },
      "source": [
        "# **Reconnaissance de visages de la base donnée**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q__seBCvvf3u",
        "outputId": "4c028e26-0712-4931-86e0-003a83848840"
      },
      "source": [
        "!pip install face_recognition"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting face_recognition\n",
            "  Downloading https://files.pythonhosted.org/packages/1e/95/f6c9330f54ab07bfa032bf3715c12455a381083125d8880c43cbe76bb3d0/face_recognition-1.3.0-py2.py3-none-any.whl\n",
            "Collecting face-recognition-models>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cf/3b/4fd8c534f6c0d1b80ce0973d01331525538045084c73c153ee6df20224cf/face_recognition_models-0.3.0.tar.gz (100.1MB)\n",
            "\u001b[K     |████████████████████████████████| 100.2MB 42kB/s \n",
            "\u001b[?25hRequirement already satisfied: Click>=6.0 in /usr/local/lib/python3.6/dist-packages (from face_recognition) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from face_recognition) (1.19.5)\n",
            "Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.6/dist-packages (from face_recognition) (19.18.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from face_recognition) (7.0.0)\n",
            "Building wheels for collected packages: face-recognition-models\n",
            "  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566173 sha256=0531f98cfcf06362bf95fbbdfa337ae716fe0d6f5995bd14c1724aa25beb1dd8\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/99/18/59c6c8f01e39810415c0e63f5bede7d83dfb0ffc039865465f\n",
            "Successfully built face-recognition-models\n",
            "Installing collected packages: face-recognition-models, face-recognition\n",
            "Successfully installed face-recognition-1.3.0 face-recognition-models-0.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeDyV2V-vy0O"
      },
      "source": [
        "import face_recognition\n",
        "import numpy as np\n",
        "import shutil\n",
        "import os\n",
        "import smtplib\n",
        "import imghdr\n",
        "import cv2\n",
        "import time\n",
        "from email.mime.multipart import MIMEMultipart\n",
        "from email.mime.text import MIMEText\n",
        "from email.mime.base import MIMEBase\n",
        "from email import encoders"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQzsqONxwUnU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d35e125c-81d3-496a-b7cb-7f3c039e13cb"
      },
      "source": [
        "known_face_encodings = []\n",
        "known_face_names = []\n",
        "i=0\n",
        "directory = r'/content/opencv/known_faces'\n",
        "for filename in os.listdir(directory):\n",
        "  image = face_recognition.load_image_file(os.path.join(directory, filename))\n",
        "  face_encoding = face_recognition.face_encodings(image)[0]\n",
        "  known_face_encodings.append(face_encoding)\n",
        "  known_face_names.append(filename[:-4])\n",
        "  print(\"reconnaissance terminée avec succès pour \"+filename[:-4])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "reconnaissance terminée avec succès pour achraf\n",
            "reconnaissance terminée avec succès pour ahmed\n",
            "reconnaissance terminée avec succès pour nadine\n",
            "reconnaissance terminée avec succès pour jhon\n",
            "reconnaissance terminée avec succès pour maria\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fx7ALRxVbEF"
      },
      "source": [
        "# **Définiton de la fonction autorisation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFT1rIhT0tC8"
      },
      "source": [
        "def autorisation():\n",
        "  test = 0\n",
        "  dir = r'/content/opencv/testing'\n",
        "  for file in os.listdir(dir):\n",
        "    # Load an image with an unknown face\n",
        "    unknown_image = face_recognition.load_image_file(os.path.join(dir, file))\n",
        "    name = \"unknown\"\n",
        "    # Find all the faces and face encodings in the unknown image\n",
        "    face_locations = face_recognition.face_locations(unknown_image)\n",
        "    face_encodings = face_recognition.face_encodings(unknown_image, face_locations)\n",
        "    os.remove(os.path.join(dir, file))\n",
        "    # Loop through each face found in the unknown image\n",
        "    for face_encoding in face_encodings:\n",
        "      # See if the face is a match for the known face(s)\n",
        "      matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
        "      # Or instead, use the known face with the smallest distance to the new face\n",
        "      face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
        "      best_match_index = np.argmin(face_distances)\n",
        "      if matches[best_match_index]:\n",
        "        name = known_face_names[best_match_index]\n",
        "        test = 1\n",
        "        break\n",
        "  return name\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqCVwnE4RVdG"
      },
      "source": [
        "# **Définition de la fonction send_known**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZP6IjHK-ndR"
      },
      "source": [
        "def send_known(name):\n",
        "  from email.message import EmailMessage\n",
        "  content =  name + \" a tenté d'obtenir l'accès pour entrer.\"\n",
        "  EMAIL_ADDRESS = 'computervison.enis@gmail.com'\n",
        "  EMAIL_PASSWORD = 'projetopencv2020'\n",
        "\n",
        "  contacts = ['achraf.tarifa@enis.tn']\n",
        "  for i in contacts : \n",
        "    msg = EmailMessage()\n",
        "    msg['Subject'] = \"TENTATIVE D'ACCES\"\n",
        "    msg['From'] = EMAIL_ADDRESS\n",
        "    msg['To'] = i\n",
        "    msg.set_content(content)\n",
        "    with smtplib.SMTP_SSL('smtp.gmail.com', 465) as smtp:\n",
        "      smtp.login(EMAIL_ADDRESS, EMAIL_PASSWORD)\n",
        "      smtp.send_message(msg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTuepTV2chW8"
      },
      "source": [
        "# **Définition de la fonction send_unknown**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fNH_hJ8XZKr"
      },
      "source": [
        "def send_unknown():\n",
        "  fromaddr = 'computervison.enis@gmail.com'\n",
        "  toaddr = 'achraf.tarifa@enis.tn'\n",
        "\n",
        "  msg = MIMEMultipart()\n",
        "\n",
        "  msg['From'] = fromaddr\n",
        "  msg['To'] = toaddr\n",
        "  msg['Subject'] = \"ALERTE!!\"\n",
        "\n",
        "  body = \"Une personne inconnue a tenté d'obtenir l'accès pour entrer.\"\n",
        "  dire = r'/content/opencv/unknown'\n",
        "  msg.attach(MIMEText(body, 'plain'))\n",
        "  for file in os.listdir(dire):\n",
        "    filename = file\n",
        "    attachment = open(os.path.join(dire, file),\"rb\")\n",
        "    part = MIMEBase('application', 'octet-stream')\n",
        "    part.set_payload((attachment).read())\n",
        "    encoders.encode_base64(part)\n",
        "    part.add_header('Content-Disposition', \"attachment; filename= %s\" % filename)\n",
        "    msg.attach(part)\n",
        "    server = smtplib.SMTP('smtp.gmail.com', 587)\n",
        "    server.starttls()\n",
        "    server.login(fromaddr, 'projetopencv2020')\n",
        "    text = msg.as_string()\n",
        "    server.sendmail(fromaddr, toaddr, text)\n",
        "    os.remove(os.path.join(dire, file))\n",
        "  server.quit()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdfongX-U-Zd"
      },
      "source": [
        "# **Lecture video ou live cam et détection des visages**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nty9TF-MF5uP"
      },
      "source": [
        "#cap = cv2.VideoCapture(0) for live cam\n",
        "cap = cv2.VideoCapture('/content/opencv/test2.3gpp')\n",
        "t_end = time.time()\n",
        "face_cascade = cv2.CascadeClassifier('/content/opencv/haarcascade_frontalface_default.xml')\n",
        "count = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3X9p-uQGDhD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "422f0ce9-8e03-464d-b67c-414f8a0963f1"
      },
      "source": [
        "while True:\n",
        "    _, img = cap.read()\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)    \n",
        "    faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
        "    if faces != () :\n",
        "      for (x, y, w, h) in faces:\n",
        "        #cv2.imwrite(\"/content/opencv/ff/fr%d.jpg\" % count, img)\n",
        "        if(time.time()>=t_end):\n",
        "            cv2.imwrite(\"/content/opencv/testing/frame%d.jpg\" % count, img)\n",
        "            count = count + 1\n",
        "            nom = autorisation()\n",
        "            if nom!=\"unknown\":\n",
        "              send_known(nom)\n",
        "              print(nom)\n",
        "              count = 0\n",
        "              t_end = time.time()+60\n",
        "            else :\n",
        "              print(nom)\n",
        "              if(count>15):\n",
        "                cv2.imwrite(\"/content/opencv/unknown/frame%d.jpg\" % count, img)\n",
        "                send_unknown()\n",
        "                count = 0\n",
        "                t_end = time.time()+60"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "unknown\n",
            "unknown\n",
            "unknown\n",
            "unknown\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-475ef4b90c56>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mgray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mfaces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_cascade\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetectMultiScale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfaces\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfaces\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}